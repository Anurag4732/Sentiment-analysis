{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk, re, scipy\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from spellchecker import SpellChecker \n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics import f1_score, classification_report, accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   label                                              tweet\n",
       " 0      0  #fingerprint #pregnancy test https://goo.gl/h1...\n",
       " 1      0  finally a transparant silicon case ^^ thanks t...\n",
       " 2      0  we love this! would you go? #talk #makememorie..., (7920, 2))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('C:/Users/Anurag/Downloads/sentiment_data_analytic_vidya.csv').drop('id', axis = 1)\n",
    "df['tweet'] = df['tweet'].map(lambda x : x.lower())\n",
    "df.head(3), df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.iloc[:4000].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def punch(x):\n",
    "    x = re.sub(r\"[-()\\\"#/@;:@*<>{}`ð'+=~£|¦â.!%+-^$?,0-9]\",\"\", x)\n",
    "    x = re.sub('$&@*#', 'vulgar', x) # Mention in data \n",
    "    x = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", x) #expand 'k' to '000' eg. 50k to 50000\n",
    "    x = re.sub(\"\\\\n\", ' ', x)\n",
    "    x = re.sub(\"\\W\", ' ', x)\n",
    "    x = re.sub(\"\\'s\", \" \", x) \n",
    "    x = re.sub(\"whats\", \"what is\", x, flags=re.IGNORECASE)\n",
    "    x = re.sub(\"\\'ve\", \"have\", x)\n",
    "    x = re.sub(\"can't\", \"can not\", x)\n",
    "    x = re.sub(\"n't\", \"not\", x)\n",
    "    x = re.sub(\"i'm\", \"i am\", x, flags = re.IGNORECASE)\n",
    "    x = re.sub(\"\\'re\", \"are\", x)\n",
    "    x = re.sub(\"\\'d\", \"would\", x)\n",
    "    x = re.sub(r\"http\\S+\", \"\", str(x))\n",
    "    x = re.sub(\"e\\.g\\.\", \"eg\", x, flags = re.IGNORECASE)\n",
    "    x = re.sub(\"e-mail\", \"email\", x, flags = re.IGNORECASE)\n",
    "    x = re.sub(r\"e - mail\", \"email\", x)\n",
    "    x = re.sub(r\"US\", \"America\", x)\n",
    "    x = re.sub(r\"USA\", \"America\", x)\n",
    "    x = re.sub(r\"us\", \"America\", x)\n",
    "    x = re.sub(r\"usa\", \"America\", x)\n",
    "    x = re.sub(r\"Chinese\", \"China\", x)\n",
    "    x = re.sub(r\"india\", \"India\", x)\n",
    "    x = re.sub(\"im\", \"i am\", x, flags = re.IGNORECASE)\n",
    "    x = re.sub(\"its\", \"it is\", x, flags= re.IGNORECASE)\n",
    "    x = re.sub(\"shes\", \"she is\", x, flags = re.IGNORECASE)\n",
    "    x = re.sub(\"u\", \"you\", x, flags = re.IGNORECASE)\n",
    "    x = re.sub(\"ur\", \"you are\", x, flags = re.IGNORECASE)\n",
    "    x = re.sub(\"wouldnt\", \"would not\", x, flags = re.IGNORECASE)\n",
    "    x = re.sub(\"youve\",  \"you have\", x, flags = re.IGNORECASE)\n",
    "    x = re.sub(r\"\\s{2,}\", \" \", x) # Remove extra space between words\n",
    "    x = x.strip() # Remove extra space from begning and ending\n",
    "    \n",
    "    return(x)\n",
    "\n",
    "df1['tweet'] = df1['tweet'].map(lambda x : punch(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(x):\n",
    "    return(' '.join([word for word in nltk.word_tokenize(x) if word not in stopwords.words('english')]))\n",
    "\n",
    "def get_char_length_ratio(x): #To find how much word has meaningful content\n",
    "    return len(x['tweet'])/max(1,len(x['tweet_without_stop_words']))\n",
    "\n",
    "def get_Levenshtein(string1,string2): # Calculate Levenshtein distance to measure similiarity between string(edit base)\n",
    "    import editdistance\n",
    "    return editdistance.eval(string1,string2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['tweet_without_stop_words'] = df1['tweet'].map(lambda x : remove_stopwords(x))\n",
    "df1['char_length_ratio'] = df1.apply(lambda x : get_char_length_ratio(x), axis = 1)\n",
    "df1['leve_distance'] = df1.apply(lambda x : get_Levenshtein(x['tweet'], x['tweet_without_stop_words']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lexicon model based rating:-\n",
    "from nltk.corpus import opinion_lexicon\n",
    "pos_list = set(opinion_lexicon.positive())\n",
    "neg_list = set(opinion_lexicon.negative())\n",
    "\n",
    "sentiment = []\n",
    "for x in df1['tweet_without_stop_words']:\n",
    "    marks = 0\n",
    "    for j in nltk.word_tokenize(x):\n",
    "        if j in pos_list:\n",
    "            marks += 1\n",
    "        elif j in neg_list:\n",
    "            marks -= 1\n",
    "    sentiment.append(marks)\n",
    "df1['lexicon_rating'] = sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Char langth ratio is imp, 1 contain high langth ratio distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "var = plt.hist(df1[df1['label'] == 1]['char_length_ratio'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "var = plt.hist(df1[df1['label'] == 0]['char_length_ratio'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Levenshte distance plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = plt.hist(df1[df1['label'] == 1]['leve_distance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = plt.hist(df1[df1['label'] == 0]['leve_distance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_without_stop_words</th>\n",
       "      <th>char_length_ratio</th>\n",
       "      <th>leve_distance</th>\n",
       "      <th>lexicon_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>fingerprint pregnancy test android apps beayou...</td>\n",
       "      <td>fingerprint pregnancy test android apps beayou...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>finally a transparant silicon case thanks to m...</td>\n",
       "      <td>finally transparant silicon case thanks youncl...</td>\n",
       "      <td>1.131579</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>we love this woyould yoyou go talk makememorie...</td>\n",
       "      <td>love woyould yoyou go talk makememories younpl...</td>\n",
       "      <td>1.091954</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                              tweet  \\\n",
       "0      0  fingerprint pregnancy test android apps beayou...   \n",
       "1      0  finally a transparant silicon case thanks to m...   \n",
       "2      0  we love this woyould yoyou go talk makememorie...   \n",
       "\n",
       "                            tweet_without_stop_words  char_length_ratio  \\\n",
       "0  fingerprint pregnancy test android apps beayou...           1.000000   \n",
       "1  finally transparant silicon case thanks youncl...           1.131579   \n",
       "2  love woyould yoyou go talk makememories younpl...           1.091954   \n",
       "\n",
       "   leve_distance  lexicon_rating  \n",
       "0              0               0  \n",
       "1             10               1  \n",
       "2              8               1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4000x2184 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 33817 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(stop_words = 'english', max_df = 0.99, strip_accents = 'unicode', ngram_range=(1, 1), min_df = 3) \n",
    "temp = tfidf.fit_transform(df1['tweet'])\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2178</th>\n",
       "      <th>2179</th>\n",
       "      <th>2180</th>\n",
       "      <th>2181</th>\n",
       "      <th>2182</th>\n",
       "      <th>2183</th>\n",
       "      <th>char_length_ratio</th>\n",
       "      <th>leve_distance</th>\n",
       "      <th>lexicon_rating</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.131579</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.091954</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 2188 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9  ...  2178  2179  2180  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "\n",
       "   2181  2182  2183  char_length_ratio  leve_distance  lexicon_rating  label  \n",
       "0   0.0   0.0   0.0           1.000000              0               0      0  \n",
       "1   0.0   0.0   0.0           1.131579             10               1      0  \n",
       "2   0.0   0.0   0.0           1.091954              8               1      0  \n",
       "\n",
       "[3 rows x 2188 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_new = pd.DataFrame(temp.toarray())\n",
    "df1_new['char_length_ratio'] = df1['char_length_ratio']\n",
    "df1_new['leve_distance'] = df1['leve_distance']\n",
    "df1_new['lexicon_rating'] = df1['lexicon_rating']\n",
    "df1_new['label'] = df1['label']\n",
    "\n",
    "df1_new.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 2188)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dev, x_final, y_dev, y_final = train_test_split(df1_new.iloc[:,:-1], df1_new['label'], test_size = 0.1, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2880, 2187), (2880,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_dev, y_dev, test_size = 0.2, random_state = 42)\n",
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "                       max_depth=50, max_features='sqrt', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
       "                       n_jobs=None, oob_score=True, random_state=42, verbose=0,\n",
       "                       warm_start=True)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
    "                       max_depth=50, max_features='sqrt', max_leaf_nodes=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=1, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, n_estimators = 500,\n",
    "                       n_jobs=None, oob_score = True, random_state=42, verbose=0,\n",
    "                       warm_start= True)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\anurag\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\sklearn\\ensemble\\forest.py:307: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7197802197802198"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train)\n",
    "pred = model.predict(x_test)\n",
    "\n",
    "y_pred = []\n",
    "for i in pred:\n",
    "    if i <= 0.5:\n",
    "        y_pred.append(0)\n",
    "    else:\n",
    "        y_pred.append(1)\n",
    "\n",
    "f1_score(y_test, np.array(y_pred).reshape(y_test.shape))\n",
    "#0.7297"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[494,  42],\n",
       "       [ 59, 125]], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[481,  55],\n",
       "       [ 53, 131]], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
    "                       max_depth=50, max_features='sqrt', max_leaf_nodes=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=1, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, n_estimators=410,\n",
    "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
    "                       warm_start=False)\n",
    "0.7178082191780822\n",
    "[[494,  42],\n",
    "       [ 59, 125]],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7280701754385965"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## MultiNaive Bayes:-\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model = MultinomialNB(alpha=.4)\n",
    "\n",
    "model.fit(x_train.iloc[:,:-1], y_train)\n",
    "pred = model.predict(x_test.iloc[:,:-1])\n",
    "\n",
    "y_pred = []\n",
    "for i in pred:\n",
    "    if i <= 0.5:\n",
    "        y_pred.append(0)\n",
    "    else:\n",
    "        y_pred.append(1)\n",
    "\n",
    "f1_score(y_test, np.array(y_pred).reshape(y_test.shape))\n",
    "#0.7297"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perameter Tuning:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "                       max_depth=50, max_features='sqrt', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=410,\n",
      "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
      "                       warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import make_scorer, f1_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Choose the type of classifier. \n",
    "model = RandomForestClassifier(random_state = 42)\n",
    "\n",
    "# Choose some parameter combinations to try\n",
    "# learning_rate = [0.2, 0.22, 0.25] #  \n",
    "criterion = ['entropy']\n",
    "# splitter = ['best', 'random']\n",
    "n_estimators = [350, 390, 410, 430, 450,471] # ,\n",
    "max_depth = [43, 45, 47, 50, 53, 60] #, \n",
    "max_features = ['sqrt'] # \n",
    "# min_samples_leaf = [11,13,15,17]\n",
    "# max_leaf_nodes = [5, 6, 7]\n",
    "parameters = {'criterion' : criterion,  'n_estimators' : n_estimators,\n",
    "             'max_depth': max_depth, 'max_features' : max_features }\n",
    "               \n",
    "\n",
    "# bootstrap=True, class_weight=None, criterion='entropy',\n",
    "#                        max_depth=15, max_features='auto', max_leaf_nodes=None,\n",
    "#                        min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "#                        min_samples_leaf=1, min_samples_split=2,\n",
    "#                        min_weight_fraction_leaf=0.0, n_estimators=200,\n",
    "#                        n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
    "#                        warm_start=False\n",
    "\n",
    "# Type of scoring used to compare parameter combinations\n",
    "acc_scorer = make_scorer(f1_score, greater_is_better=True)\n",
    "\n",
    "# Run the grid search\n",
    "grid_obj = RandomizedSearchCV(estimator = model, param_distributions = parameters, scoring = acc_scorer, cv = 3)\n",
    "grid_obj = grid_obj.fit(x_train, y_train)\n",
    "\n",
    "# Set the clf to the best combination of parameters\n",
    "model = grid_obj.best_estimator_\n",
    "\n",
    "# # Fit the best algorithm to the data. \n",
    "model.fit(x_train, y_train)\n",
    "print(model)\n",
    "# print()\n",
    "pred = model.predict(x_test)\n",
    "# # print(model.score(x_train, y_train))\n",
    "# # print(model.score(x_test, y_test))\n",
    "# # print(model.feature_importances_)\n",
    "# # print(np.sqrt(metrics.mean_squared_error(y_test, pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7178082191780822"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.fit(x_train, y_train)\n",
    "# pred = model.predict(x_test)\n",
    "\n",
    "y_pred = []\n",
    "for i in pred:\n",
    "    if i <= 0.5:\n",
    "        y_pred.append(0)\n",
    "    else:\n",
    "        y_pred.append(1)\n",
    "\n",
    "f1_score(y_test, np.array(y_pred).reshape(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=45, max_features='sqrt', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=350,\n",
       "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bootstrap=True, class_weight=None, criterion='entropy',\n",
    "                       max_depth=50, max_features='sqrt', max_leaf_nodes=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=1, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, n_estimators=410,\n",
    "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
    "                       warm_start=False)\n",
    "    0.71780821"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Data:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1953, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('test_sentiment-analytic.csv')\n",
    "id_ = df_test['id']\n",
    "df_test.drop('id', axis = 1, inplace = True)\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2187"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2187"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def punch(x):\n",
    "    x = re.sub(r\"[-()\\\"#/@;:@*<>{}`ð'+=~£|¦â.!%+-^$?,0-9]\",\"\", x)\n",
    "    x = re.sub('$&@*#', 'vulgar', x) # Mention in data \n",
    "    x = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", x) #expand 'k' to '000' eg. 50k to 50000\n",
    "    x = re.sub(\"\\\\n\", ' ', x)\n",
    "    x = re.sub(\"\\W\", ' ', x)\n",
    "    x = re.sub(\"\\'s\", \" \", x) \n",
    "    x = re.sub(\"whats\", \"what is\", x, flags=re.IGNORECASE)\n",
    "    x = re.sub(\"\\'ve\", \"have\", x)\n",
    "    x = re.sub(\"can't\", \"can not\", x)\n",
    "    x = re.sub(\"n't\", \"not\", x)\n",
    "    x = re.sub(\"i'm\", \"i am\", x, flags = re.IGNORECASE)\n",
    "    x = re.sub(\"\\'re\", \"are\", x)\n",
    "    x = re.sub(\"\\'d\", \"would\", x)\n",
    "    x = re.sub(r\"http\\S+\", \"\", str(x))\n",
    "    x = re.sub(\"e\\.g\\.\", \"eg\", x, flags = re.IGNORECASE)\n",
    "    x = re.sub(\"e-mail\", \"email\", x, flags = re.IGNORECASE)\n",
    "    x = re.sub(r\"e - mail\", \"email\", x)\n",
    "    x = re.sub(r\"US\", \"America\", x)\n",
    "    x = re.sub(r\"USA\", \"America\", x)\n",
    "    x = re.sub(r\"us\", \"America\", x)\n",
    "    x = re.sub(r\"usa\", \"America\", x)\n",
    "    x = re.sub(r\"Chinese\", \"China\", x)\n",
    "    x = re.sub(r\"india\", \"India\", x)\n",
    "    x = re.sub(\"im\", \"i am\", x, flags = re.IGNORECASE)\n",
    "    x = re.sub(\"its\", \"it is\", x, flags= re.IGNORECASE)\n",
    "    x = re.sub(\"shes\", \"she is\", x, flags = re.IGNORECASE)\n",
    "    x = re.sub(\"u\", \"you\", x, flags = re.IGNORECASE)\n",
    "    x = re.sub(\"ur\", \"you are\", x, flags = re.IGNORECASE)\n",
    "    x = re.sub(\"wouldnt\", \"would not\", x, flags = re.IGNORECASE)\n",
    "    x = re.sub(\"youve\",  \"you have\", x, flags = re.IGNORECASE)\n",
    "    x = re.sub(r\"\\s{2,}\", \" \", x) # Remove extra space between words\n",
    "    x = x.strip() # Remove extra space from begning and ending\n",
    "    \n",
    "    return(x)\n",
    "\n",
    "def remove_stopwords(x):\n",
    "    return(' '.join([word for word in nltk.word_tokenize(x) if word not in stopwords.words('english')]))\n",
    "\n",
    "def get_char_length_ratio(x): #To find how much word has meaningful content\n",
    "    return len(x['tweet'])/max(1,len(x['tweet_without_stop_words']))\n",
    "\n",
    "def get_Levenshtein(string1,string2): # Calculate Levenshtein distance to measure similiarity between string(edit base)\n",
    "    import editdistance\n",
    "    return editdistance.eval(string1,string2)\n",
    "\n",
    "############################################################\n",
    "df_test['tweet'] = df_test['tweet'].map(lambda x : punch(x))\n",
    "df_test['tweet_without_stop_words'] = df_test['tweet'].map(lambda x : remove_stopwords(x))\n",
    "df_test['char_length_ratio'] = df_test.apply(lambda x : get_char_length_ratio(x), axis = 1)\n",
    "df_test['leve_distance'] = df_test.apply(lambda x : get_Levenshtein(x['tweet'], x['tweet_without_stop_words']), axis = 1)\n",
    "\n",
    "## Lexicon model based rating:-\n",
    "from nltk.corpus import opinion_lexicon\n",
    "pos_list = set(opinion_lexicon.positive())\n",
    "neg_list = set(opinion_lexicon.negative())\n",
    "\n",
    "sentiment = []\n",
    "for x in df_test['tweet_without_stop_words']:\n",
    "    marks = 0\n",
    "    for j in nltk.word_tokenize(x):\n",
    "        if j in pos_list:\n",
    "            marks += 1\n",
    "        elif j in neg_list:\n",
    "            marks -= 1\n",
    "    sentiment.append(marks)\n",
    "df_test['lexicon_rating'] = sentiment\n",
    "##############################################################\n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words = 'english', max_df = 0.99, strip_accents = 'unicode', ngram_range=(1, 1), min_df = 3) \n",
    "temp = tfidf.fit_transform(df_test['tweet'])\n",
    "\n",
    "df1_new = pd.DataFrame(temp.toarray())\n",
    "df1_new['char_length_ratio'] = df_test['char_length_ratio']\n",
    "df1_new['leve_distance'] = df_test['leve_distance']\n",
    "df1_new['lexicon_rating'] = df_test['lexicon_rating']\n",
    "# df1_new['label'] = df_test['label']\n",
    "\n",
    "# model.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# f1_score(y_test, np.array(y_pred).reshape(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1953, 1314)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "872"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2186-1314"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(np.concatenate([np.concatenate([df1_new.iloc[:,:1315].values, np.zeros((1953, 869), dtype = np.float)],axis = 1), df1_new.iloc[:, -3:]], axis = 1))\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for i in pred:\n",
    "    if i <= 0.5:\n",
    "        y_pred.append(0)\n",
    "    else:\n",
    "        y_pred.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame({'id':id_})\n",
    "result['label'] = y_pred\n",
    "result.to_csv('result3_test_analytic.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7921</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>7922</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>7923</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>7924</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>7925</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1948</td>\n",
       "      <td>9869</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1949</td>\n",
       "      <td>9870</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>9871</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1951</td>\n",
       "      <td>9872</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1952</td>\n",
       "      <td>9873</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1953 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  label\n",
       "0     7921      0\n",
       "1     7922      0\n",
       "2     7923      0\n",
       "3     7924      1\n",
       "4     7925      0\n",
       "...    ...    ...\n",
       "1948  9869      0\n",
       "1949  9870      0\n",
       "1950  9871      0\n",
       "1951  9872      0\n",
       "1952  9873      0\n",
       "\n",
       "[1953 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('C:\\\\Users\\Anurag\\Downloads\\\\result4_test_analytic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7921</td>\n",
       "      <td>I hate the new #iphone upgrade. Won't let me d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>7922</td>\n",
       "      <td>currently shitting my fucking pants. #apple #i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>7923</td>\n",
       "      <td>I'd like to puts some CD-ROMS on my iPad, is t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>7924</td>\n",
       "      <td>My ipod is officially dead. I lost all my pict...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>7925</td>\n",
       "      <td>Been fighting iTunes all night! I only want th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1948</td>\n",
       "      <td>9869</td>\n",
       "      <td>#SamsungGalaxyNote7 Explodes, Burns 6-Year-Old...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1949</td>\n",
       "      <td>9870</td>\n",
       "      <td>Now Available - Hoodie. Check it out here - ht...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>9871</td>\n",
       "      <td>There goes a crack right across the screen. If...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1951</td>\n",
       "      <td>9872</td>\n",
       "      <td>@codeofinterest as i said #Adobe big time we m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1952</td>\n",
       "      <td>9873</td>\n",
       "      <td>Finally I got it .. thanx my father .. #Samsun...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1953 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                              tweet\n",
       "0     7921  I hate the new #iphone upgrade. Won't let me d...\n",
       "1     7922  currently shitting my fucking pants. #apple #i...\n",
       "2     7923  I'd like to puts some CD-ROMS on my iPad, is t...\n",
       "3     7924  My ipod is officially dead. I lost all my pict...\n",
       "4     7925  Been fighting iTunes all night! I only want th...\n",
       "...    ...                                                ...\n",
       "1948  9869  #SamsungGalaxyNote7 Explodes, Burns 6-Year-Old...\n",
       "1949  9870  Now Available - Hoodie. Check it out here - ht...\n",
       "1950  9871  There goes a crack right across the screen. If...\n",
       "1951  9872  @codeofinterest as i said #Adobe big time we m...\n",
       "1952  9873  Finally I got it .. thanx my father .. #Samsun...\n",
       "\n",
       "[1953 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('test_sentiment-analytic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
